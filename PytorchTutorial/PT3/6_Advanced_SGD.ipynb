{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:24:25.274323Z",
     "start_time": "2018-07-23T10:24:24.903045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x106552af0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as vdatasets\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "import pickle,os,shutil\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Gradient descent?\n",
    "참고\n",
    "- http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:24:25.282528Z",
     "start_time": "2018-07-23T10:24:25.276138Z"
    }
   },
   "outputs": [],
   "source": [
    "port= '6006'\n",
    "try:\n",
    "    shutil.rmtree('runs/')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:24:25.341511Z",
     "start_time": "2018-07-23T10:24:25.284244Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE= 64\n",
    "\n",
    "train_dataset = vdatasets.MNIST(root='../data/MNIST/',\n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2,\n",
    "                                           drop_last=True) # 이동평균이 튀는걸 방지\n",
    "\n",
    "test_dataset = vdatasets.MNIST(root='../data/MNIST/',\n",
    "                               train=False, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:24:25.359116Z",
     "start_time": "2018-07-23T10:24:25.343352Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.linear1= nn.Linear(input_size, hidden_size)\n",
    "        self.linear2= nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3= nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # In : {배치사이즈, 차원수} => Out : (배치사이즈, 차원수)\n",
    "        self.bn1= nn.BatchNorm1d(hidden_size)\n",
    "        self.bn2= nn.BatchNorm1d(hidden_size)\n",
    "    def forward(self, inputs):\n",
    "        outputs= self.bn1(self.linear1(inputs))\n",
    "        outputs= F.relu(outputs)\n",
    "        outputs= self.bn2(self.linear2(outputs))\n",
    "        outputs= F.relu(outputs)\n",
    "        return self.linear3(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:24:25.371802Z",
     "start_time": "2018-07-23T10:24:25.360897Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCH=5\n",
    "LR=0.1\n",
    "\n",
    "INPUT_SIZE= 784\n",
    "HIDDEN_SIZE= 512\n",
    "OUTPUT_SIZE=10\n",
    "\n",
    "model=NN(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "loss_function= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:29:06.473272Z",
     "start_time": "2018-07-23T10:29:06.461888Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd= optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "sgd_momentum = optim.SGD(model.parameters(),lr=LR,momentum=0.9)\n",
    "sgd_nesterov_momentum = optim.SGD(model.parameters(),lr=LR,momentum=0.9,nesterov=True)\n",
    "\n",
    "adagrad = optim.Adagrad(model.parameters(),lr=LR)\n",
    "rmsprop = optim.RMSprop(model.parameters(),lr=LR,alpha=0.99)\n",
    "adam = optim.Adam(model.parameters(),lr=LR,betas=(0.9,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:34:40.301550Z",
     "start_time": "2018-07-23T10:34:40.298709Z"
    }
   },
   "outputs": [],
   "source": [
    "a= sgd.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:31:22.591842Z",
     "start_time": "2018-07-23T10:31:22.588816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'torch.optim.sgd.SGD'>\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:40:59.427369Z",
     "start_time": "2018-07-23T10:36:13.465224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd training start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a408109/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "sgd_momentum training start!\n",
      "done\n",
      "sgd_nesterov_momentum training start!\n",
      "done\n",
      "adagrad training start!\n",
      "done\n",
      "rmsprop training start!\n",
      "done\n",
      "adam training start!\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "EPOCH=5\n",
    "LR=0.1\n",
    "HIDDEN_SIZE = 512\n",
    "OPTIM_OPS = ['sgd', 'sgd_momentum', 'sgd_nesterov_momentum', 'adagrad',\n",
    "            'rmsprop', 'adam'] \n",
    "\n",
    "for op_name in OPTIM_OPS:\n",
    "    writer = SummaryWriter(comment=\"-\"+op_name)\n",
    "    \n",
    "    model = NN(784, HIDDEN_SIZE, 10)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    exec('optimizer= {}'.format(op_name))\n",
    "    \n",
    "    # 트레이닝\n",
    "    print(op_name + \" training start!\")\n",
    "    for epoch in range(EPOCH):\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = Variable(inputs).view(-1,784), Variable(targets)\n",
    "            model.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            writer.add_scalars('data/optimizer/',{op_name : loss.data[0]},(i+1)+(epoch*len(train_loader)))\n",
    "    print(\"done\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T10:41:30.795086Z",
     "start_time": "2018-07-23T10:41:30.791500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6006'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-23T10:41:31.245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/a408109/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "TensorBoard 1.9.0 at http://408109-HC-D16A57:6006 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir runs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
